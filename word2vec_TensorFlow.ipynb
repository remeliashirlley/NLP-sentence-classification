{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34338148",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ad2dafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras import models, layers, optimizers\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "import gensim.downloader\n",
    "\n",
    "from datetime import datetime\n",
    "from packaging import version\n",
    "from tensorflow import keras\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7147ffbc",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "805c8b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this cell if you want to generate a new validation set\n",
    "df = pd.read_csv(\"trec/original/train.csv\")\n",
    "# TODO: check w group if we need this\n",
    "# Remove duplicates from train\n",
    "df.drop_duplicates(subset='text', keep='first', inplace=True)\n",
    "# Randomly choose 500 rows to drop \n",
    "num_rows_to_drop = 500\n",
    "np.random.seed(42)\n",
    "rows_to_drop = np.random.choice(df.index, num_rows_to_drop, replace=False)\n",
    "# print(rows_to_drop)\n",
    "# Create a development dataframe from these 500 dropped rows\n",
    "validation_df = df.loc[rows_to_drop].copy()\n",
    "\n",
    "# Reset index of development dataframe and export to csv\n",
    "validation_df.reset_index(drop=True, inplace=True)\n",
    "validation_df.to_csv(\"trec/generated/validation.csv\",index=None)\n",
    "\n",
    "df_copy = df.copy(deep=True)\n",
    "# Drop validation rows from original dataset, export as csv\n",
    "df_copy.drop(rows_to_drop, inplace=True)\n",
    "df_copy.reset_index(drop=True, inplace=True)\n",
    "df_copy.to_csv(\"trec/generated/train.csv\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b52f612b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set and train sets are unique\n"
     ]
    }
   ],
   "source": [
    "# Run this cell if you're generating a new validation set for sanity checking\n",
    "def check_unique_texts(train_csv_file, validation_csv_file):\n",
    "    train_df = pd.read_csv(train_csv_file)\n",
    "    validation_df = pd.read_csv(validation_csv_file)\n",
    "\n",
    "    train_texts = train_df['text']\n",
    "    validation_texts = validation_df['text']\n",
    "\n",
    "    common_texts = validation_texts[validation_texts.isin(train_texts)]\n",
    "\n",
    "    if common_texts.empty:\n",
    "        print(\"Validation set and train sets are unique\")\n",
    "    else:\n",
    "        print(\"Common values found in the 'text' column:\")\n",
    "        print(common_texts)\n",
    "\n",
    "train_csv_file = \"trec/generated/train.csv\"\n",
    "validation_csv_file = \"trec/generated/validation.csv\"\n",
    "check_unique_texts(train_csv_file, validation_csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e95b05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for duplicates from test - remove if there are any\n",
    "df = pd.read_csv(\"trec/original/test.csv\")\n",
    "df.drop_duplicates(subset='text', keep='first', inplace=True)\n",
    "df.to_csv('trec/generated/test.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f43aa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_csv('trec/generated/train.csv')\n",
    "val_df=pd.read_csv('trec/generated/validation.csv')\n",
    "test_df=pd.read_csv('trec/generated/test.csv')\n",
    "\n",
    "train_df.drop(columns='label-fine', inplace=True)\n",
    "val_df.drop(columns='label-fine', inplace=True)\n",
    "test_df.drop(columns='label-fine', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "face8c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label-coarse\n",
      "1    1132\n",
      "3    1091\n",
      "0    1051\n",
      "4     781\n",
      "5     746\n",
      "2      80\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "value_counts = train_df['label-coarse'].value_counts()\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0fe211",
   "metadata": {},
   "source": [
    "### Assign 2 random classes to OTHERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4cfc483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly selected OTHERS classes:  [5 1]\n"
     ]
    }
   ],
   "source": [
    "classes=train_df['label-coarse'].unique()\n",
    "random.shuffle(classes)\n",
    "print('Randomly selected OTHERS classes: ',classes[:2])\n",
    "\n",
    "for i in classes[:2]:\n",
    "    train_df['label-coarse']=train_df['label-coarse'].apply(lambda x:'OTHERS' if x==i else x)\n",
    "    val_df['label-coarse']=val_df['label-coarse'].apply(lambda x:'OTHERS' if x==i else x)\n",
    "    test_df['label-coarse']=test_df['label-coarse'].apply(lambda x:'OTHERS' if x==i else x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90f1d90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 'OTHERS' 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "print(train_df['label-coarse'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b01cb9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping Dictionary:  {0: 0, 2: 1, 3: 2, 4: 3, 'OTHERS': 4}\n"
     ]
    }
   ],
   "source": [
    "mapping_dict = {item: idx for idx, item in enumerate(set(train_df['label-coarse'].unique()))}\n",
    "train_df['label-coarse']=train_df['label-coarse'].apply(lambda x:mapping_dict[x])\n",
    "val_df['label-coarse']=val_df['label-coarse'].apply(lambda x:mapping_dict[x])\n",
    "test_df['label-coarse']=test_df['label-coarse'].apply(lambda x:mapping_dict[x])\n",
    "\n",
    "print('Mapping Dictionary: ',mapping_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09496a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 4 1 2 3]\n",
      "[2 0 4 3 1]\n",
      "[3 4 2 0 1]\n"
     ]
    }
   ],
   "source": [
    "for df in [train_df,val_df,test_df]:\n",
    "    print(df['label-coarse'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027876e1",
   "metadata": {},
   "source": [
    "### word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f7c2d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_model = gensim.downloader.load('word2vec-google-news-300')\n",
    "\n",
    "max_sequence_length = 100  # Define the maximum sequence length\n",
    "\n",
    "def tokenize_and_vectorize(texts, word_vectors, max_sequence_length):\n",
    "    sequences = []\n",
    "    for text in texts:\n",
    "        words = text.split()\n",
    "        word_vectors_list = []\n",
    "        for word in words:\n",
    "            if word in word_vectors:\n",
    "                word_vectors_list.append(word_vectors[word])\n",
    "        sequences.append(word_vectors_list)\n",
    "\n",
    "    X = pad_sequences(sequences, maxlen=max_sequence_length, dtype='float32')\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd4dd3c",
   "metadata": {},
   "source": [
    "### Tokenize and vectorize features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e1aa878",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_features=lambda df:tokenize_and_vectorize(df['text'],wv_model,max_sequence_length)\n",
    "\n",
    "X_train=process_features(train_df)\n",
    "X_val=process_features(val_df)\n",
    "X_test=process_features(test_df)\n",
    "\n",
    "y_train = np.array(train_df['label-coarse'])\n",
    "y_val = np.array(val_df['label-coarse'])\n",
    "y_test = np.array(test_df['label-coarse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d6a338",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b406c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_max_pooling_model(units):\n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.LSTM(units, return_sequences=True),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),  # Max pooling layer\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(5, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def lstm_avg_pooling_model(units):\n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.LSTM(units, return_sequences=True),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),  # Max pooling layer\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(5, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def simple_lstm_model(units):\n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.LSTM(units),\n",
    "    tf.keras.layers.Dense(5, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def max_pooling_model(hidden_size,output_size):\n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.GlobalMaxPooling1D(),  # Max pooling over the sequence\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(hidden_size, activation='relu'),\n",
    "    tf.keras.layers.Dense(output_size, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def avg_pooling_model(hidden_size,output_size):\n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),  \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(hidden_size, activation='relu'),\n",
    "    tf.keras.layers.Dense(hidden_size, activation='relu'),\n",
    "    tf.keras.layers.Dense(output_size, activation='softmax')\n",
    "    ])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368b80d4",
   "metadata": {},
   "source": [
    "### Find optimal hyperparamters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e506da2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_hyperparameters(param_grid,model_type):\n",
    "    # Initialize early stopping\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "\n",
    "    # Initialize best model and best loss\n",
    "    best_model = None\n",
    "    best_loss = np.inf\n",
    "\n",
    "    # Iterate over the parameter grid\n",
    "    for params in ParameterGrid(param_grid):\n",
    "        units = params['hidden_size']\n",
    "\n",
    "        if model_type=='lstm_max_pooling':\n",
    "            model=lstm_max_pooling_model(units)\n",
    "        elif model_type=='lstm_avg_pooling':\n",
    "            model=lstm_avg_pooling_model(units)\n",
    "        elif model_type=='simple_lstm':\n",
    "            model=simple_lstm_model(units)\n",
    "        elif model_type=='max_pooling':\n",
    "            model=max_pooling_model(units,output_size=5)\n",
    "        elif model_type=='avg_pooling':\n",
    "            model=avg_pooling_model(units,output_size=5)\n",
    "\n",
    "        model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "        # Train the model with early stopping\n",
    "        history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, batch_size=32, callbacks=[early_stopping], verbose=0)\n",
    "\n",
    "        # Evaluate the model on the validation set\n",
    "        val_loss = history.history['val_loss'][-1]\n",
    "\n",
    "        # Check if the current model is the best\n",
    "        if val_loss < best_loss:\n",
    "            best_model = model\n",
    "            best_loss = val_loss\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "    \n",
    "    # Train the best model on the full training set\n",
    "    best_model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, batch_size=32, callbacks=[early_stopping, tensorboard_callback], verbose=1)\n",
    "    predictions = best_model.predict(X_test)\n",
    "    print(model.summary())\n",
    "\n",
    "    print(f'Training Runtime: {time.time()-start_time:.2f} seconds')\n",
    "    print(f'Train Accuracy: {max(history.history[\"accuracy\"]) * 100:.2f}%')\n",
    "\n",
    "    # Evaluate the best model on the test set\n",
    "    test_loss, test_accuracy = best_model.evaluate(X_test, y_test)\n",
    "    print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea073fe3",
   "metadata": {},
   "source": [
    "### Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1d99b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(param_grid,model_type):\n",
    "    predictions=find_optimal_hyperparameters(param_grid,model_type)\n",
    "\n",
    "    predicted_labels = np.argmax(predictions, axis=1)\n",
    "    label_counts = np.bincount(predicted_labels)\n",
    "\n",
    "    # Print the number of values for each label\n",
    "    for label, count in enumerate(label_counts):\n",
    "        print(f\"Label {label}: {count} instances\")\n",
    "\n",
    "    confusion_matrix = multilabel_confusion_matrix(y_test, predicted_labels)\n",
    "    confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e93b617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter grid for tuning\n",
    "param_grid = {\n",
    "    'hidden_size': [64, 128, 256],  # hidden size\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6926cc98",
   "metadata": {},
   "source": [
    "### LSTM with max pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f10401ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: early stopping\n",
      "Epoch 11: early stopping\n",
      "Epoch 12: early stopping\n",
      "Epoch 1/100\n",
      "153/153 [==============================] - 6s 39ms/step - loss: 0.1299 - accuracy: 0.9557 - val_loss: 0.3777 - val_accuracy: 0.8980\n",
      "Epoch 2/100\n",
      "153/153 [==============================] - 6s 40ms/step - loss: 0.0929 - accuracy: 0.9709 - val_loss: 0.3985 - val_accuracy: 0.9040\n",
      "Epoch 3/100\n",
      "153/153 [==============================] - 6s 36ms/step - loss: 0.0857 - accuracy: 0.9728 - val_loss: 0.3907 - val_accuracy: 0.9080\n",
      "Epoch 4/100\n",
      "153/153 [==============================] - 6s 38ms/step - loss: 0.0615 - accuracy: 0.9816 - val_loss: 0.4185 - val_accuracy: 0.8940\n",
      "Epoch 5/100\n",
      "153/153 [==============================] - 6s 37ms/step - loss: 0.0574 - accuracy: 0.9824 - val_loss: 0.4051 - val_accuracy: 0.9000\n",
      "Epoch 6/100\n",
      "153/153 [==============================] - 6s 36ms/step - loss: 0.0455 - accuracy: 0.9891 - val_loss: 0.4351 - val_accuracy: 0.9000\n",
      "Epoch 6: early stopping\n",
      "16/16 [==============================] - 0s 13ms/step\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 100, 256)          570368    \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPoolin  (None, 50, 256)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 12800)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 64005     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 634373 (2.42 MB)\n",
      "Trainable params: 634373 (2.42 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Training Runtime: 35.42 seconds\n",
      "Train Accuracy: 98.73%\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.2558 - accuracy: 0.9240\n",
      "Test Accuracy: 92.40%\n",
      "Label 0: 143 instances\n",
      "Label 1: 9 instances\n",
      "Label 2: 68 instances\n",
      "Label 3: 106 instances\n",
      "Label 4: 174 instances\n"
     ]
    }
   ],
   "source": [
    "train(param_grid,'lstm_max_pooling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33761b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-6fa8064226e500cc\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-6fa8064226e500cc\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421cfbbc",
   "metadata": {},
   "source": [
    "### LSTM with average pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cfbd3b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: early stopping\n",
      "Epoch 31: early stopping\n",
      "Epoch 19: early stopping\n",
      "Epoch 1/100\n",
      "153/153 [==============================] - 10s 62ms/step - loss: 0.1612 - accuracy: 0.9555 - val_loss: 0.4418 - val_accuracy: 0.8980\n",
      "Epoch 2/100\n",
      "153/153 [==============================] - 9s 61ms/step - loss: 0.1648 - accuracy: 0.9566 - val_loss: 0.6355 - val_accuracy: 0.8140\n",
      "Epoch 3/100\n",
      "153/153 [==============================] - 10s 62ms/step - loss: 0.1935 - accuracy: 0.9437 - val_loss: 0.3999 - val_accuracy: 0.9080\n",
      "Epoch 4/100\n",
      "153/153 [==============================] - 9s 60ms/step - loss: 0.1567 - accuracy: 0.9586 - val_loss: 0.4280 - val_accuracy: 0.9060\n",
      "Epoch 5/100\n",
      "153/153 [==============================] - 9s 60ms/step - loss: 0.1740 - accuracy: 0.9553 - val_loss: 0.4542 - val_accuracy: 0.9020\n",
      "Epoch 6/100\n",
      "153/153 [==============================] - 9s 60ms/step - loss: 0.1430 - accuracy: 0.9633 - val_loss: 0.4788 - val_accuracy: 0.9020\n",
      "Epoch 7/100\n",
      "153/153 [==============================] - 9s 61ms/step - loss: 0.1334 - accuracy: 0.9670 - val_loss: 0.4782 - val_accuracy: 0.9020\n",
      "Epoch 8/100\n",
      "153/153 [==============================] - 9s 61ms/step - loss: 0.1327 - accuracy: 0.9666 - val_loss: 0.4809 - val_accuracy: 0.9000\n",
      "Epoch 8: early stopping\n",
      "16/16 [==============================] - 1s 23ms/step\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_7 (LSTM)               (None, 100, 256)          570368    \n",
      "                                                                 \n",
      " global_average_pooling1d_4  (None, 256)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 5)                 1285      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 571653 (2.18 MB)\n",
      "Trainable params: 571653 (2.18 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Training Runtime: 75.56 seconds\n",
      "Train Accuracy: 94.06%\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3678 - accuracy: 0.8960\n",
      "Test Accuracy: 89.60%\n",
      "Label 0: 174 instances\n",
      "Label 1: 7 instances\n",
      "Label 2: 64 instances\n",
      "Label 3: 97 instances\n",
      "Label 4: 158 instances\n"
     ]
    }
   ],
   "source": [
    "train(param_grid,'lstm_avg_pooling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea0b5875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-ceff94a81aac317\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-ceff94a81aac317\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21e1232",
   "metadata": {},
   "source": [
    "### Simple LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3deac8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: early stopping\n",
      "Epoch 12: early stopping\n",
      "Epoch 12: early stopping\n",
      "Epoch 1/100\n",
      "153/153 [==============================] - 6s 36ms/step - loss: 0.0624 - accuracy: 0.9809 - val_loss: 0.4077 - val_accuracy: 0.8980\n",
      "Epoch 2/100\n",
      "153/153 [==============================] - 6s 36ms/step - loss: 0.0565 - accuracy: 0.9848 - val_loss: 0.4007 - val_accuracy: 0.9000\n",
      "Epoch 3/100\n",
      "153/153 [==============================] - 5s 35ms/step - loss: 0.0512 - accuracy: 0.9834 - val_loss: 0.4086 - val_accuracy: 0.8960\n",
      "Epoch 4/100\n",
      "153/153 [==============================] - 5s 34ms/step - loss: 0.0872 - accuracy: 0.9723 - val_loss: 0.4161 - val_accuracy: 0.9060\n",
      "Epoch 5/100\n",
      "153/153 [==============================] - 5s 35ms/step - loss: 0.0451 - accuracy: 0.9859 - val_loss: 0.4130 - val_accuracy: 0.8920\n",
      "Epoch 6/100\n",
      "153/153 [==============================] - 5s 35ms/step - loss: 0.0322 - accuracy: 0.9908 - val_loss: 0.4294 - val_accuracy: 0.8860\n",
      "Epoch 7/100\n",
      "153/153 [==============================] - 5s 36ms/step - loss: 0.0219 - accuracy: 0.9955 - val_loss: 0.4433 - val_accuracy: 0.8940\n",
      "Epoch 7: early stopping\n",
      "16/16 [==============================] - 0s 13ms/step\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_10 (LSTM)              (None, 256)               570368    \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 5)                 1285      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 571653 (2.18 MB)\n",
      "Trainable params: 571653 (2.18 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Training Runtime: 38.73 seconds\n",
      "Train Accuracy: 98.14%\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.2366 - accuracy: 0.9300\n",
      "Test Accuracy: 93.00%\n",
      "Label 0: 139 instances\n",
      "Label 1: 11 instances\n",
      "Label 2: 65 instances\n",
      "Label 3: 108 instances\n",
      "Label 4: 177 instances\n"
     ]
    }
   ],
   "source": [
    "train(param_grid,'simple_lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2cd9497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 72661), started 0:13:27 ago. (Use '!kill 72661' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-10cefb34922e07d3\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-10cefb34922e07d3\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8df2ed",
   "metadata": {},
   "source": [
    "### Max pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e47ff1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: early stopping\n",
      "Epoch 21: early stopping\n",
      "Epoch 11: early stopping\n",
      "Epoch 1/100\n",
      "153/153 [==============================] - 0s 2ms/step - loss: 0.5635 - accuracy: 0.7781 - val_loss: 0.7146 - val_accuracy: 0.7200\n",
      "Epoch 2/100\n",
      "153/153 [==============================] - 0s 1ms/step - loss: 0.5623 - accuracy: 0.7816 - val_loss: 0.7080 - val_accuracy: 0.7160\n",
      "Epoch 3/100\n",
      "153/153 [==============================] - 0s 1ms/step - loss: 0.5622 - accuracy: 0.7789 - val_loss: 0.7067 - val_accuracy: 0.7160\n",
      "Epoch 4/100\n",
      "153/153 [==============================] - 0s 1ms/step - loss: 0.5488 - accuracy: 0.7859 - val_loss: 0.7227 - val_accuracy: 0.7240\n",
      "Epoch 5/100\n",
      "153/153 [==============================] - 0s 1ms/step - loss: 0.5567 - accuracy: 0.7865 - val_loss: 0.7014 - val_accuracy: 0.7220\n",
      "Epoch 6/100\n",
      "153/153 [==============================] - 0s 1ms/step - loss: 0.5535 - accuracy: 0.7824 - val_loss: 0.7092 - val_accuracy: 0.7240\n",
      "Epoch 7/100\n",
      "153/153 [==============================] - 0s 1ms/step - loss: 0.5468 - accuracy: 0.7892 - val_loss: 0.7151 - val_accuracy: 0.7200\n",
      "Epoch 8/100\n",
      "153/153 [==============================] - 0s 1ms/step - loss: 0.5387 - accuracy: 0.7918 - val_loss: 0.7328 - val_accuracy: 0.7180\n",
      "Epoch 9/100\n",
      "153/153 [==============================] - 0s 1ms/step - loss: 0.5362 - accuracy: 0.7937 - val_loss: 0.7138 - val_accuracy: 0.7280\n",
      "Epoch 10/100\n",
      "153/153 [==============================] - 0s 1ms/step - loss: 0.5333 - accuracy: 0.7931 - val_loss: 0.7168 - val_accuracy: 0.7240\n",
      "Epoch 10: early stopping\n",
      "16/16 [==============================] - 0s 743us/step\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " global_max_pooling1d_2 (Gl  (None, 300)               0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 300)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 256)               77056     \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 5)                 1285      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 78341 (306.02 KB)\n",
      "Trainable params: 78341 (306.02 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Training Runtime: 2.30 seconds\n",
      "Train Accuracy: 77.05%\n",
      "16/16 [==============================] - 0s 910us/step - loss: 0.5355 - accuracy: 0.7980\n",
      "Test Accuracy: 79.80%\n",
      "Label 0: 147 instances\n",
      "Label 1: 8 instances\n",
      "Label 2: 66 instances\n",
      "Label 3: 94 instances\n",
      "Label 4: 185 instances\n"
     ]
    }
   ],
   "source": [
    "train(param_grid,'max_pooling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bab8addf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 72661), started 0:16:20 ago. (Use '!kill 72661' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-fc7c3973fa3356d5\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-fc7c3973fa3356d5\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4daeb0e",
   "metadata": {},
   "source": [
    "### Average pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "848c3b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: early stopping\n",
      "Epoch 27: early stopping\n",
      "Epoch 19: early stopping\n",
      "Epoch 1/100\n",
      "153/153 [==============================] - 0s 3ms/step - loss: 0.3285 - accuracy: 0.8793 - val_loss: 0.5947 - val_accuracy: 0.7860\n",
      "Epoch 2/100\n",
      "153/153 [==============================] - 0s 2ms/step - loss: 0.3211 - accuracy: 0.8814 - val_loss: 0.5987 - val_accuracy: 0.7820\n",
      "Epoch 3/100\n",
      "153/153 [==============================] - 0s 2ms/step - loss: 0.3002 - accuracy: 0.8928 - val_loss: 0.6351 - val_accuracy: 0.7720\n",
      "Epoch 4/100\n",
      "153/153 [==============================] - 0s 2ms/step - loss: 0.2961 - accuracy: 0.8906 - val_loss: 0.5934 - val_accuracy: 0.7920\n",
      "Epoch 5/100\n",
      "153/153 [==============================] - 0s 2ms/step - loss: 0.2720 - accuracy: 0.9043 - val_loss: 0.5965 - val_accuracy: 0.7920\n",
      "Epoch 6/100\n",
      "153/153 [==============================] - 0s 2ms/step - loss: 0.2557 - accuracy: 0.9064 - val_loss: 0.5971 - val_accuracy: 0.7840\n",
      "Epoch 7/100\n",
      "153/153 [==============================] - 0s 2ms/step - loss: 0.2482 - accuracy: 0.9166 - val_loss: 0.6298 - val_accuracy: 0.7880\n",
      "Epoch 8/100\n",
      "153/153 [==============================] - 0s 2ms/step - loss: 0.2290 - accuracy: 0.9234 - val_loss: 0.6066 - val_accuracy: 0.7860\n",
      "Epoch 9/100\n",
      "153/153 [==============================] - 0s 2ms/step - loss: 0.2193 - accuracy: 0.9240 - val_loss: 0.6554 - val_accuracy: 0.7700\n",
      "Epoch 9: early stopping\n",
      "16/16 [==============================] - 0s 994us/step\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " global_average_pooling1d_7  (None, 300)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " flatten_13 (Flatten)        (None, 300)               0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 256)               77056     \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 5)                 1285      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 144133 (563.02 KB)\n",
      "Trainable params: 144133 (563.02 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Training Runtime: 2.76 seconds\n",
      "Train Accuracy: 87.28%\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4352 - accuracy: 0.8480\n",
      "Test Accuracy: 84.80%\n",
      "Label 0: 161 instances\n",
      "Label 1: 10 instances\n",
      "Label 2: 64 instances\n",
      "Label 3: 100 instances\n",
      "Label 4: 165 instances\n"
     ]
    }
   ],
   "source": [
    "train(param_grid,'avg_pooling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "41f39b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 72661), started 0:17:08 ago. (Use '!kill 72661' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-24ec1b730ec2297\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-24ec1b730ec2297\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc7395c",
   "metadata": {},
   "source": [
    "###  Averaging over word representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7a56d89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_vectors(sentence, wv_model):\n",
    "    words = sentence.split()\n",
    "    vectors = [wv_model[word] if word in wv_model else np.zeros(300) for word in words]\n",
    "    return np.mean(vectors, axis=0)\n",
    "\n",
    "process_mean_features=lambda df:np.array([sentence_to_vectors(sentence,wv_model) for sentence in df['text']])\n",
    "\n",
    "X_train=process_mean_features(train_df)\n",
    "X_val=process_mean_features(val_df)\n",
    "X_test=process_mean_features(test_df)\n",
    "\n",
    "y_train = np.array(train_df['label-coarse'])\n",
    "y_val = np.array(val_df['label-coarse'])\n",
    "y_test = np.array(test_df['label-coarse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2b4999f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "153/153 [==============================] - 0s 1ms/step - loss: 1.1007 - accuracy: 0.5526 - val_loss: 0.7587 - val_accuracy: 0.6980\n",
      "Epoch 2/100\n",
      "153/153 [==============================] - 0s 767us/step - loss: 0.6896 - accuracy: 0.7353 - val_loss: 0.5973 - val_accuracy: 0.7720\n",
      "Epoch 3/100\n",
      "153/153 [==============================] - 0s 756us/step - loss: 0.5725 - accuracy: 0.7837 - val_loss: 0.5548 - val_accuracy: 0.7840\n",
      "Epoch 4/100\n",
      "153/153 [==============================] - 0s 764us/step - loss: 0.5131 - accuracy: 0.8050 - val_loss: 0.5503 - val_accuracy: 0.7700\n",
      "Epoch 5/100\n",
      "153/153 [==============================] - 0s 780us/step - loss: 0.4715 - accuracy: 0.8203 - val_loss: 0.6044 - val_accuracy: 0.7520\n",
      "Epoch 6/100\n",
      "153/153 [==============================] - 0s 756us/step - loss: 0.4440 - accuracy: 0.8343 - val_loss: 0.5563 - val_accuracy: 0.7600\n",
      "Epoch 7/100\n",
      "153/153 [==============================] - 0s 752us/step - loss: 0.4113 - accuracy: 0.8498 - val_loss: 0.5302 - val_accuracy: 0.7760\n",
      "Epoch 8/100\n",
      "153/153 [==============================] - 0s 782us/step - loss: 0.3841 - accuracy: 0.8570 - val_loss: 0.5185 - val_accuracy: 0.7880\n",
      "Epoch 9/100\n",
      "153/153 [==============================] - 0s 786us/step - loss: 0.3609 - accuracy: 0.8681 - val_loss: 0.5400 - val_accuracy: 0.7900\n",
      "Epoch 10/100\n",
      "153/153 [==============================] - 0s 772us/step - loss: 0.3392 - accuracy: 0.8734 - val_loss: 0.5373 - val_accuracy: 0.7920\n",
      "Epoch 11/100\n",
      "153/153 [==============================] - 0s 776us/step - loss: 0.3137 - accuracy: 0.8877 - val_loss: 0.5339 - val_accuracy: 0.7840\n",
      "Epoch 12/100\n",
      "153/153 [==============================] - 0s 761us/step - loss: 0.2889 - accuracy: 0.8976 - val_loss: 0.5447 - val_accuracy: 0.7800\n",
      "Epoch 13/100\n",
      "153/153 [==============================] - 0s 760us/step - loss: 0.2725 - accuracy: 0.9039 - val_loss: 0.5450 - val_accuracy: 0.7760\n",
      "Epoch 13: early stopping\n",
      "16/16 [==============================] - 0s 465us/step - loss: 0.3283 - accuracy: 0.8740\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=300, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(5, activation='softmax')) \n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=32, callbacks=[early_stopping,tensorboard_callback], epochs=100)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "664750b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 72661), started 0:24:58 ago. (Use '!kill 72661' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-efcf6cb7736465c3\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-efcf6cb7736465c3\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
