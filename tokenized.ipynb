{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: pip\n"
     ]
    }
   ],
   "source": [
    "! pip install pandas\n",
    "! pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this cell if you want to generate a new validation set\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"trec/original/train.csv\")\n",
    "# TODO: check w group if we need this\n",
    "# Remove duplicates from train\n",
    "df.drop_duplicates(subset='text', keep='first', inplace=True)\n",
    "# Randomly choose 500 rows to drop \n",
    "num_rows_to_drop = 500\n",
    "np.random.seed(42)\n",
    "rows_to_drop = np.random.choice(df.index, num_rows_to_drop, replace=False)\n",
    "# print(rows_to_drop)\n",
    "# Create a development dataframe from these 500 dropped rows\n",
    "validation_df = df.loc[rows_to_drop].copy()\n",
    "\n",
    "# Reset index of development dataframe and export to csv\n",
    "validation_df.reset_index(drop=True, inplace=True)\n",
    "validation_df.to_csv(\"trec/generated/validation.csv\")\n",
    "\n",
    "df_copy = df.copy(deep=True)\n",
    "# Drop validation rows from original dataset, export as csv\n",
    "df_copy.drop(rows_to_drop, inplace=True)\n",
    "df_copy.reset_index(drop=True, inplace=True)\n",
    "df_copy.to_csv(\"trec/generated/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set and train sets are unique\n"
     ]
    }
   ],
   "source": [
    "# Run this cell if you're generating a new validation set for sanity checking\n",
    "def check_unique_texts(train_csv_file, validation_csv_file):\n",
    "    train_df = pd.read_csv(train_csv_file)\n",
    "    validation_df = pd.read_csv(validation_csv_file)\n",
    "\n",
    "    train_texts = train_df['text']\n",
    "    validation_texts = validation_df['text']\n",
    "\n",
    "    common_texts = validation_texts[validation_texts.isin(train_texts)]\n",
    "\n",
    "    if common_texts.empty:\n",
    "        print(\"Validation set and train sets are unique\")\n",
    "    else:\n",
    "        print(\"Common values found in the 'text' column:\")\n",
    "        print(common_texts)\n",
    "\n",
    "train_csv_file = \"trec/generated/train.csv\"\n",
    "validation_csv_file = \"trec/generated/validation.csv\"\n",
    "check_unique_texts(train_csv_file, validation_csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for duplicates from test - remove if there are any\n",
    "df = pd.read_csv(\"trec/original/test.csv\")\n",
    "df.drop_duplicates(subset='text', keep='first', inplace=True)\n",
    "df.to_csv('trec/generated/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label-coarse</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>How did serfdom develop in and then leave Russ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>What films featured the character Popeye Doyle ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>How can I find a list of celebrities ' real na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>What fowl grabs the spotlight after the Chines...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>What is the full form of .com ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5447</th>\n",
       "      <td>1</td>\n",
       "      <td>What 's the shape of a camel 's spine ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5448</th>\n",
       "      <td>1</td>\n",
       "      <td>What type of currency is used in China ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5449</th>\n",
       "      <td>4</td>\n",
       "      <td>What is the temperature today ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5450</th>\n",
       "      <td>4</td>\n",
       "      <td>What is the temperature for cooking ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5451</th>\n",
       "      <td>1</td>\n",
       "      <td>What currency is used in Australia ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5452 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label-coarse                                               text\n",
       "0                0  How did serfdom develop in and then leave Russ...\n",
       "1                1   What films featured the character Popeye Doyle ?\n",
       "2                0  How can I find a list of celebrities ' real na...\n",
       "3                1  What fowl grabs the spotlight after the Chines...\n",
       "4                2                    What is the full form of .com ?\n",
       "...            ...                                                ...\n",
       "5447             1            What 's the shape of a camel 's spine ?\n",
       "5448             1           What type of currency is used in China ?\n",
       "5449             4                    What is the temperature today ?\n",
       "5450             4              What is the temperature for cooking ?\n",
       "5451             1               What currency is used in Australia ?\n",
       "\n",
       "[5452 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df=pd.read_csv('trec/original/train.csv')\n",
    "train_df.drop(columns='label-fine', inplace=True)\n",
    "test_df=df.copy()\n",
    "test_df.drop(columns='label-fine', inplace=True)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 'OTHERS', 3, 5], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "classes=train_df['label-coarse'].unique()\n",
    "random.shuffle(classes)\n",
    "for i in classes[:2]:\n",
    "    train_df['label-coarse']=train_df['label-coarse'].apply(lambda x:'OTHERS' if x==i else x)\n",
    "    test_df['label-coarse']=test_df['label-coarse'].apply(lambda x:'OTHERS' if x==i else x)\n",
    "\n",
    "train_df['label-coarse'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label-coarse</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>How far is it from Denver to Aspen ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>What county is Modesto , California in ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Who was Galileo ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>What is an atom ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>When did Hawaii become a state ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>2</td>\n",
       "      <td>Who was the 22nd President of the US ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>1</td>\n",
       "      <td>What is the money they use in Zambia ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>4</td>\n",
       "      <td>How many feet in a mile ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>1</td>\n",
       "      <td>What is the birthstone of October ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0</td>\n",
       "      <td>What is e-coli ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label-coarse                                      text\n",
       "0               4      How far is it from Denver to Aspen ?\n",
       "1               3  What county is Modesto , California in ?\n",
       "2               2                         Who was Galileo ?\n",
       "3               0                         What is an atom ?\n",
       "4               4          When did Hawaii become a state ?\n",
       "..            ...                                       ...\n",
       "495             2    Who was the 22nd President of the US ?\n",
       "496             1    What is the money they use in Zambia ?\n",
       "497             4                 How many feet in a mile ?\n",
       "498             1       What is the birthstone of October ?\n",
       "499             0                          What is e-coli ?\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_dict = {item: idx for idx, item in enumerate(set(train_df['label-coarse'].unique()))}\n",
    "train_df['label-coarse']=train_df['label-coarse'].apply(lambda x:mapping_dict[x])\n",
    "test_df['label-coarse']=test_df['label-coarse'].apply(lambda x:mapping_dict[x])\n",
    "\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "def iter_df(df):\n",
    "    for _,x in df.iterrows(): \n",
    "        yield tuple(x)\n",
    "\n",
    "train_iter=iter_df(train_df)\n",
    "\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "\n",
    "def yield_tokens(data_iter):\n",
    "    for _, text in data_iter:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline = lambda x:vocab(tokenizer(x))\n",
    "label_pipeline = lambda x:int(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list, offsets = [], [], [0]\n",
    "    for _label, _text in batch:\n",
    "        label_list.append(label_pipeline(_label))\n",
    "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "        text_list.append(processed_text)\n",
    "        offsets.append(processed_text.size(0))\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    text_list = torch.cat(text_list)\n",
    "    return label_list.to(device), text_list.to(device), offsets.to(device)\n",
    "\n",
    "train_iter=iter_df(train_df)\n",
    "dataloader=DataLoader(train_iter, batch_size=8, shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassificationModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=False)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        return self.fc(embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter=iter_df(train_df)\n",
    "num_class = len(set([label for (label, text) in train_iter]))\n",
    "vocab_size = len(vocab)\n",
    "emsize = 64\n",
    "model = TextClassificationModel(vocab_size, emsize, num_class).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(dataloader):\n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    log_interval = 500\n",
    "    start_time = time.time()\n",
    "\n",
    "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        predicted_label = model(text, offsets)\n",
    "        loss = criterion(predicted_label, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "        total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "        total_count += label.size(0)\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print(\n",
    "                \"| epoch {:3d} | {:5d}/{:5d} batches \"\n",
    "                \"| accuracy {:8.3f}\".format(\n",
    "                    epoch, idx, len(dataloader), total_acc / total_count\n",
    "                )\n",
    "            )\n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "\n",
    "\n",
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "            predicted_label = model(text, offsets)\n",
    "            loss = criterion(predicted_label, label)\n",
    "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_acc / total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "| end of epoch   1 | time:  0.33s | valid accuracy    0.936 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   2 | time:  0.35s | valid accuracy    0.936 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   3 | time:  0.35s | valid accuracy    0.934 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   4 | time:  0.37s | valid accuracy    0.934 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   5 | time:  0.37s | valid accuracy    0.934 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   6 | time:  0.36s | valid accuracy    0.934 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   7 | time:  0.33s | valid accuracy    0.934 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   8 | time:  0.35s | valid accuracy    0.934 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   9 | time:  0.33s | valid accuracy    0.934 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  10 | time:  0.32s | valid accuracy    0.934 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  11 | time:  0.33s | valid accuracy    0.934 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  12 | time:  0.35s | valid accuracy    0.934 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  13 | time:  0.36s | valid accuracy    0.934 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  14 | time:  0.36s | valid accuracy    0.934 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  15 | time:  0.32s | valid accuracy    0.934 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  16 | time:  0.31s | valid accuracy    0.934 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  17 | time:  0.31s | valid accuracy    0.934 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  18 | time:  0.34s | valid accuracy    0.934 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  19 | time:  0.32s | valid accuracy    0.934 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  20 | time:  0.32s | valid accuracy    0.934 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  21 | time:  0.36s | valid accuracy    0.934 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  22 | time:  0.32s | valid accuracy    0.934 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  23 | time:  0.32s | valid accuracy    0.934 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  24 | time:  0.32s | valid accuracy    0.934 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  25 | time:  0.32s | valid accuracy    0.934 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  26 | time:  0.32s | valid accuracy    0.934 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  27 | time:  0.33s | valid accuracy    0.934 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  28 | time:  0.32s | valid accuracy    0.934 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  29 | time:  0.32s | valid accuracy    0.934 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  30 | time:  0.32s | valid accuracy    0.934 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  31 | time:  0.32s | valid accuracy    0.934 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  32 | time:  0.32s | valid accuracy    0.934 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  33 | time:  0.32s | valid accuracy    0.934 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  34 | time:  0.31s | valid accuracy    0.934 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  35 | time:  0.32s | valid accuracy    0.934 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  36 | time:  0.32s | valid accuracy    0.934 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  37 | time:  0.31s | valid accuracy    0.934 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  38 | time:  0.32s | valid accuracy    0.934 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  39 | time:  0.32s | valid accuracy    0.934 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  40 | time:  0.32s | valid accuracy    0.934 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  41 | time:  0.32s | valid accuracy    0.934 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  42 | time:  0.32s | valid accuracy    0.934 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  43 | time:  0.32s | valid accuracy    0.934 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  44 | time:  0.32s | valid accuracy    0.934 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  45 | time:  0.32s | valid accuracy    0.934 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  46 | time:  0.31s | valid accuracy    0.934 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  47 | time:  0.31s | valid accuracy    0.934 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  48 | time:  0.32s | valid accuracy    0.934 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  49 | time:  0.32s | valid accuracy    0.934 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  50 | time:  0.32s | valid accuracy    0.934 \n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data.dataset import random_split\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "\n",
    "# Hyperparameters\n",
    "EPOCHS = 50  # epoch\n",
    "LR = 0.01  # learning rate\n",
    "BATCH_SIZE = 32  # batch size for training\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
    "total_accu = None\n",
    "train_iter, test_iter = iter_df(train_df), iter_df(test_df)\n",
    "\n",
    "train_dataset = to_map_style_dataset(train_iter)\n",
    "test_dataset = to_map_style_dataset(test_iter)\n",
    "num_train = int(len(train_dataset)-500)\n",
    "split_train_, split_valid_ = random_split(\n",
    "    train_dataset, [num_train, len(train_dataset) - num_train]\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    split_train_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
    ")\n",
    "valid_dataloader = DataLoader(\n",
    "    split_valid_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
    ")\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(train_dataloader)\n",
    "    accu_val = evaluate(valid_dataloader)\n",
    "    if total_accu is not None and total_accu > accu_val:\n",
    "        scheduler.step()\n",
    "    else:\n",
    "        total_accu = accu_val\n",
    "    print(\"-\" * 59)\n",
    "    print(\n",
    "        \"| end of epoch {:3d} | time: {:5.2f}s | \"\n",
    "        \"valid accuracy {:8.3f} \".format(\n",
    "            epoch, time.time() - epoch_start_time, accu_val\n",
    "        )\n",
    "    )\n",
    "    print(\"-\" * 59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the results of test dataset.\n",
      "test accuracy    0.812\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking the results of test dataset.\")\n",
    "accu_test = evaluate(test_dataloader)\n",
    "print(\"test accuracy {:8.3f}\".format(accu_test))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
